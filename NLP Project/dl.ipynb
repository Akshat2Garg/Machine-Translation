{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "319f4778-874b-4eaa-aadc-697bece774fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\garga\\anaconda3\\envs\\nlp\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input,LSTM, Dense, Embedding, Attention\n",
    "from keras.layers import TimeDistributed, RepeatVector,Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import string\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "758f8787-d9b9-4f64-8297-6b625bbc86a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filepath):\n",
    "    df = pd.read_csv(filepath,encoding='utf-8')\n",
    "    print(\"Number of records:\",len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c312f7f-e588-4447-aa1b-0ddc6cc15955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 175621\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Qui ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Ça alors !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fire!</td>\n",
       "      <td>Au feu !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Help!</td>\n",
       "      <td>À l'aide !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>Saute.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stop!</td>\n",
       "      <td>Ça suffit !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stop!</td>\n",
       "      <td>Stop !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English words/sentences French words/sentences\n",
       "0                     Hi.                 Salut!\n",
       "1                    Run!                Cours !\n",
       "2                    Run!               Courez !\n",
       "3                    Who?                  Qui ?\n",
       "4                    Wow!             Ça alors !\n",
       "5                   Fire!               Au feu !\n",
       "6                   Help!             À l'aide !\n",
       "7                   Jump.                 Saute.\n",
       "8                   Stop!            Ça suffit !\n",
       "9                   Stop!                 Stop !"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_dataset(r'data.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee2b130-eb93-4a1a-bba5-346041403acf",
   "metadata": {},
   "source": [
    "# MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4876f404-831e-4538-9767-ba4b7e1f2d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = normalize('NFD',text).encode(\"ascii\",\"ignore\")\n",
    "    text = text.decode(\"UTF-8\")\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    text = text.lower()\n",
    "   \n",
    "    text = text.translate(str.maketrans('','',string.punctuation))\n",
    "   \n",
    "    re_print = re.compile('[^%s]'% re.escape(string.printable))\n",
    "    text = re_print.sub('',text)\n",
    "    \n",
    "    text = re.sub(r'[\\d]+','',text)\n",
    "    \n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1f06c9b-fdaf-4ea9-b7db-61d53558be4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi</td>\n",
       "      <td>salut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run</td>\n",
       "      <td>cours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run</td>\n",
       "      <td>courez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who</td>\n",
       "      <td>qui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wow</td>\n",
       "      <td>ca alors</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English words/sentences French words/sentences\n",
       "0                      hi                  salut\n",
       "1                     run                  cours\n",
       "2                     run                 courez\n",
       "3                     who                    qui\n",
       "4                     wow               ca alors"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy = df.copy()\n",
    "df_copy['English words/sentences'] = df_copy.loc[:,'English words/sentences'].apply(\n",
    "    lambda x:preprocess_text(x))\n",
    "df_copy['French words/sentences'] = df_copy.loc[:,'French words/sentences'].apply(\n",
    "    lambda x:preprocess_text(x))\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ab9cfb-8856-495c-91b2-e715e5fb44c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocab Size: 14407\n",
      "French Vocab Size: 28133\n",
      "Maximum length of sequences: 55\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    return tokenizer\n",
    "\n",
    "eng_tokenizer = tokenize(df_copy['English words/sentences'])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "fr_tokenizer = tokenize(df_copy['French words/sentences'])\n",
    "fr_vocab_size = len(fr_tokenizer.word_index) + 1\n",
    "\n",
    "seq_eng = eng_tokenizer.texts_to_sequences(df_copy['English words/sentences'])\n",
    "seq_fr = fr_tokenizer.texts_to_sequences(df_copy['French words/sentences'])\n",
    "\n",
    "max_length = max([len(seq) for seq in seq_eng + seq_fr])\n",
    "seq_eng_final = pad_sequences(seq_eng,maxlen=max_length,padding=\"post\")\n",
    "seq_fr_final = pad_sequences(seq_fr,maxlen=max_length,padding=\"post\")\n",
    "\n",
    "print(\"English Vocab Size:\",eng_vocab_size)\n",
    "print(\"French Vocab Size:\",fr_vocab_size)\n",
    "print(\"Maximum length of sequences:\",max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "908d98dd-12ea-43c4-85fa-687af7d95c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140496, 55), (35125, 55), (140496, 55), (35125, 55))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(seq_eng_final,\n",
    "                                                 seq_fr_final,\n",
    "                                                 test_size=0.2,\n",
    "                                                 shuffle=True,\n",
    "                                                 random_state=42)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b099ab4e-c6bb-4c8d-8e8f-89a75d1acf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\garga\\anaconda3\\envs\\nlp\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\garga\\anaconda3\\envs\\nlp\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# vector_length = 100\n",
    "\n",
    "# # Encoder\n",
    "# enc_inputs = Input(shape=(max_length,))\n",
    "# enc_embedding = Embedding(input_dim=eng_vocab_size,output_dim=vector_length)(enc_inputs)\n",
    "# enc_LSTM = LSTM(256,return_state=True)\n",
    "# enc_output,h,c = enc_LSTM(enc_embedding)\n",
    "# enc_states = [h,c]\n",
    "\n",
    "# # Decoder\n",
    "# dec_inputs = Input(shape=(max_length,))\n",
    "# dec_embedding = Embedding(input_dim=fr_vocab_size,output_dim=vector_length)(dec_inputs)\n",
    "# dec_LSTM = LSTM(256,return_sequences=True,return_state=True)\n",
    "# dec_output,_,_ = dec_LSTM(dec_embedding,initial_state=enc_states)\n",
    "\n",
    "\n",
    "# dec_dense = Dense(fr_vocab_size,activation=\"softmax\")\n",
    "# output = dec_dense(dec_output)\n",
    "\n",
    "# # Model\n",
    "# model = Model([enc_inputs,dec_inputs],output)\n",
    "# model.compile(optimizer='adam',loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df350566-e6a4-4748-bd87-941cee45141f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\garga\\anaconda3\\envs\\nlp\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\garga\\anaconda3\\envs\\nlp\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "4391/4391 [==============================] - 3539s 805ms/step - loss: 0.7417 - accuracy: 0.8990 - val_loss: 0.5957 - val_accuracy: 0.9083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c0c3c59ed0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit([X_train,X_train],y_train,epochs=1,validation_data=([X_test,X_test],y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "867cf0d0-edd4-4c22-8dee-6ac2a9582427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 55, 100)           1440700   \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 512)               731136    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " repeat_vector (RepeatVecto  (None, 55, 512)           0         \n",
      " r)                                                              \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 55, 256)           787456    \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, 55, 28133)         7230181   \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10189473 (38.87 MB)\n",
      "Trainable params: 10189473 (38.87 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "vector_length = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=eng_vocab_size,output_dim=vector_length,input_length=max_length,mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(256)))\n",
    "model.add(RepeatVector(max_length))\n",
    "model.add(LSTM(256,return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(fr_vocab_size,activation=\"softmax\")))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84de810-2f26-4925-a58a-9851543553f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\garga\\anaconda3\\envs\\nlp\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\garga\\anaconda3\\envs\\nlp\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "2465/4391 [===============>..............] - ETA: 4:30:21 - loss: 0.8948 - accuracy: 0.8870"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=5,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b624d-5007-42f3-9735-a9312398a2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translation(input_sentence):\n",
    "    input_sentence = preprocess_text(str(input_sentence))\n",
    "    input_seq = eng_tokenizer.texts_to_sequences([input_sentence])\n",
    "    input_seq_final = pad_sequences(input_seq,maxlen=max_length,padding=\"post\")\n",
    "    prediction = model.predict([input_seq_final])\n",
    "    output_translation = np.argmax(prediction,axis=-1)\n",
    "    \n",
    "    output_sentence = []\n",
    "    for i in output_translation[0]:\n",
    "        if i in fr_tokenizer.index_word:\n",
    "            output_sentence.append(fr_tokenizer.index_word[i])\n",
    "        else:\n",
    "            output_sentence.append(' ')\n",
    "    return ' '.join(output_sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c304d33a-ef59-4970-ade6-9a390370e615",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = \"How are you?\"\n",
    "translated = translation(input_sentence)\n",
    "print(f\"Input: {input_sentence}\")\n",
    "print(f\"Translated: {translated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34521b5-0d99-4a12-8b04-b72fca056f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = \"Where are you going?\"\n",
    "translated = translation(input_sentence)\n",
    "print(f\"Input: {input_sentence}\")\n",
    "print(f\"Translated: {translated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e0fb6d-2d0a-45e6-86b3-d7354a0a7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1b79c6-6296-4eef-b283-8a925ac2b919",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be3aa10-7bdb-4396-9aa9-67da0fc0bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(eng_tokenizer, open('eng_tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bc6487-d291-48f3-8e45-0fb70e2c311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(max_length, open('max_length.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf691cc-5bfe-4ddf-baf4-28bb8760cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(fr_tokenizer, open('fr_tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc19ed4-d344-4887-9f32-6a145904f1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
